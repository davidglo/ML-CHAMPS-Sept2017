{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a neural network to predict the position of body features from VR controllers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "import glob\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sbn\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the recorded data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data recorded are stored in CSV formatted files, which we read in as pandas data frames and extract the input and output features\n",
    "\n",
    "Note: The direction of the headset and controllers are stored in the data files as well, in the form of quaternions, with labels 'HeadsetQuaternionX', 'HeadsetQuaternionY', 'HeadsetQuaternionZ', 'HeadsetQuaternionW' and similar for LController and RController. If you are familiar with quaternion math (In a left-handed coordinate system), try to include these features in the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input labels are: \n",
      " HeadsetX, HeadsetY, HeadsetZ, LControllerX, LControllerY, LControllerZ, RControllerX, RControllerY, RControllerZ\n",
      "Output labels are: \n",
      " FrontX, FrontY, FrontZ, BackX, BackY, BackZ, LeftElbowX, LeftElbowY, LeftElbowZ, RightElbowX, RightElbowY, RightElbowZ, LeftKneeX, LeftKneeY, LeftKneeZ, RightKneeX, RightKneeY, RightKneeZ\n",
      "Shape of data_in: (32454, 9)\n",
      "Shape of data_out (32454, 18)\n",
      "Shape of box_scales (32454, 1)\n"
     ]
    }
   ],
   "source": [
    "# Create list of data files\n",
    "data_files = glob.glob('../../data/*_steamVRPositions_*')\n",
    "\n",
    "# The input features are XYZ positions of the headset and controllers\n",
    "input_features = ['Headset', 'LController', 'RController']\n",
    "# The output features are XYZ positions of the front, back, elbows and knees\n",
    "output_features = ['Front', 'Back', 'LeftElbow', 'RightElbow', 'LeftKnee', 'RightKnee']\n",
    "# Create the labels to be read\n",
    "input_labels = [x+y for x in input_features for y in 'XYZ']\n",
    "output_labels = [x+y for x in output_features for y in 'XYZ']\n",
    "print('Input labels are: \\n', \", \".join(input_labels))\n",
    "print('Output labels are: \\n', \", \".join(output_labels))\n",
    "\n",
    "# Read in the needed columns from the data files\n",
    "# The data is recorded with the simulation box size as a reference, which we need to read to\n",
    "# properly scale the data.\n",
    "all_input_data = []\n",
    "all_output_data = []\n",
    "all_box_scales = []\n",
    "all_player_ids = []\n",
    "# Read each data file\n",
    "for f in data_files:\n",
    "    fname = f.split('/')[-1]\n",
    "    # Keep track of the player generating the data\n",
    "    if fname[0] == 'f':\n",
    "        # Player Felix\n",
    "        player_id = 0\n",
    "    elif fname[0] == 'r':\n",
    "        # Player Rob\n",
    "        player_id = 1\n",
    "    elif fname[0] == 'l':\n",
    "        # Player Lisa\n",
    "        player_id = 2\n",
    "    elif fname[0] == 'h':\n",
    "        # Player Helen\n",
    "        player_id = 3\n",
    "    elif fname[0] == 's':\n",
    "        # Player Silvia\n",
    "        player_id = 4\n",
    "    else:\n",
    "        # Random players\n",
    "        player_id = 5\n",
    "        \n",
    "    df = pd.read_csv(f)\n",
    "    # drop rows with NaN\n",
    "    df = df.dropna()\n",
    "    all_input_data.append(df[input_labels].values)\n",
    "    all_output_data.append(df[output_labels].values)\n",
    "    all_box_scales.append(df['Scale'].values)\n",
    "    all_player_ids.extend([player_id]*len(df))\n",
    "\n",
    "# Join data together as a single array\n",
    "data_in = np.concatenate(all_input_data)\n",
    "data_out = np.concatenate(all_output_data)\n",
    "# Make box_scales a 2d-array for easier maths operations later\n",
    "box_scales = np.concatenate(all_box_scales)[:,None]\n",
    "player_ids = np.asarray(all_player_ids)\n",
    "print('Shape of data_in:', data_in.shape)\n",
    "print('Shape of data_out', data_out.shape)\n",
    "print('Shape of box_scales', box_scales.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When recording, people will move around the room (translation), change the direction they're facing (rotation) and the height will vary from person to person (height scaling). In addition, the positional data is recorded relative to the simulation box size (box scaling).\n",
    "The machine learning algorithm will be more effective if we normalise the data to a common reference, which can be done in many different ways. The way we have chosen centers each frame such that the average of the X and Z components of the headset and controllers are zero. Then we rotate such that the head is placed on the negative X-axis with Z-component of zero (we assume the head is facing the center).\n",
    "\n",
    "Note: If you can think of an alternative way of normalising the data, try to implement this and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headset Z-component min and max: -1.94289029309e-16 4.23272528138e-16\n",
      "Input data shape after removing axis: (32454, 8)\n"
     ]
    }
   ],
   "source": [
    "# Scale by VR-box size\n",
    "data_in *= box_scales\n",
    "data_out *= box_scales\n",
    "\n",
    "# Shift vertically so feet are at approx y=0\n",
    "# The floor_position is a known constant\n",
    "floor_position = 1.0\n",
    "\n",
    "# Only change the Y-components (indices 1, 4, ...)\n",
    "data_in[:,1::3] += floor_position\n",
    "data_out[:,1::3] += floor_position\n",
    "\n",
    "# Scale by each persons height from the first frame\n",
    "data_in /= data_in[0,1]\n",
    "data_out /= data_in[0,1]\n",
    "\n",
    "# Get mean x and z coordinates of head and hands\n",
    "# Store as 2d-array for easier math\n",
    "mean_x = np.mean(data_in[:,::3], axis=1)[:,None]\n",
    "mean_z = np.mean(data_in[:,2::3], axis=1)[:,None]\n",
    "\n",
    "# center the data\n",
    "data_in[:,::3] -= mean_x\n",
    "data_out[:,::3] -= mean_x\n",
    "data_in[:,2::3] -= mean_z\n",
    "data_out[:,2::3] -= mean_z\n",
    "\n",
    "# Rotate head onto the negative X-axis\n",
    "def rotate(array1, array2, angle):\n",
    "    \"\"\" Rotate anti-clockwise around (0,1,0) by angle radians.\n",
    "        X' = cos(angle) * X - sin(angle) * Z\n",
    "        Z' = sin(angle) * X + cos(angle) * Z\n",
    "    \"\"\"\n",
    "    c = np.cos(angle)\n",
    "    s = np.sin(angle)\n",
    "    array1[:,::3], array1[:,2::3] = (c * array1[:,::3] - s * array1[:,2::3], s * array1[:,::3] + c * array1[:,2::3])\n",
    "    array2[:,::3], array2[:,2::3] = (c * array2[:,::3] - s * array2[:,2::3], s * array2[:,::3] + c * array2[:,2::3])\n",
    "\n",
    "# Calculate the rotation angles (2d-array to make the math easier)\n",
    "head_angles = np.pi - np.arctan2(data_in[:,2], data_in[:,0])[:,None]\n",
    "# Rotate the input and output features\n",
    "rotate(data_in, data_out, head_angles)\n",
    "# Verify that the Z-component of the headset is now zero\n",
    "print('Headset Z-component min and max:', data_in[:,2].min(), data_in[:,2].max())\n",
    "\n",
    "# Since the Z-component is zero, we don't need it for training, and will ignore it from here on\n",
    "data_in = np.delete(data_in, 2, axis=1)\n",
    "print('Input data shape after removing axis:', data_in.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier removal\n",
    "Due to occlusion of the sensors sometimes one of the controllers will drift off. This is fine for the input features, as the occlusion can happen during use, but it's something that we'd like to remove from the output features. Here we use the IsolationForrest method implemented in scikit-learn to classify where occlusion might have occured. (http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html)\n",
    "\n",
    "Note: Other methods could be used as well. Take a look at http://scikit-learn.org/stable/modules/outlier_detection.html and try to use a different method.\n",
    "\n",
    "Note: When occlusion of a sensor happens, each drift should be constant in a specific direction (a drift at a later time might happen with a different rate in a different direction though). Try to detect outliers by using this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 1623 out of 32454 data points (5.0 %)\n"
     ]
    }
   ],
   "source": [
    "# Our estimations of the number of outliers in the output features\n",
    "outlier_fraction = 0.05\n",
    "\n",
    "# Construct and fit the isolation forrest\n",
    "clf = IsolationForest(max_samples=1.0, contamination=outlier_fraction)\n",
    "clf.fit(data_out)\n",
    "\n",
    "# Predict which frames have outliers\n",
    "prediction = clf.predict(data_out)\n",
    "\n",
    "# prediction will be -1 if the point is an outlier and 1 if it is not.\n",
    "# We convert this output to a boolean array\n",
    "inliers = np.asarray((prediction+1) // 2, dtype=bool)\n",
    "\n",
    "# Only retain the frames that isn't detected as outliers\n",
    "n_data_before = data_in.shape[0]\n",
    "data_in_pruned = data_in[inliers]\n",
    "data_out_pruned = data_out[inliers]\n",
    "player_ids_pruned = player_ids[inliers]\n",
    "n_data_after = data_in_pruned.shape[0]\n",
    "print('Removed %d out of %d data points (%.1f %%)' % (n_data_before - n_data_after, n_data_before,(1-n_data_after/n_data_before)*100 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualise the data before and after outlier removal to see if it looks like we would expect.\n",
    "\n",
    "Note: Try to change the outlier_fraction and view the effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_outliers(data, data_pruned, labels):\n",
    "    n_features = len(labels)\n",
    "    fig, axes = plt.subplots(n_features, 1)\n",
    "    \n",
    "    fig.set_size_inches(6, 3.5*n_features)\n",
    "    for i in range(n_features):\n",
    "        min_value = min(data[:,i])\n",
    "        max_value = max(data[:,i])\n",
    "        binwidth = 0.1\n",
    "        bins = np.arange(min(data[:, i]), max(data[:, i]) + binwidth, binwidth)\n",
    "        axes[i].set_yscale('log') # Set logarithmic y axis\n",
    "        axes[i].set_title('%s'%labels[i])\n",
    "        axes[i].set_ylabel('Probability density')\n",
    "        axes[i].hist(data[:, i], bins=bins, stacked=False)\n",
    "        axes[i].hist(data_pruned[:, i], bins=bins, stacked=False)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "plot_outliers(data_out, data_out_pruned, output_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training, test and validation data\n",
    "To avoid overfitting, we split the data into a training set, validation set and test set. This is known as cross validation. The training set is what the neural network is actually trained on. The hyper-parameters of the neural network (learning rate, regularisation, nodes in each layer etc.) can then be selected to optimise the predictive performance on the validation set, which has not been included in the training. This makes sure that the prediction of the neural network is transferable ie. still performs well on people not included in the training.\n",
    "Finally, the test set is used to measure the performance of the selected model.\n",
    "\n",
    "To keep things simple we use Felix' data as validation set and Silvia's data as test set. More robust ways of performing cross validation can be used, which you can read more about at http://scikit-learn.org/stable/modules/cross_validation.html and http://scikit-learn.org/stable/tutorial/statistical_inference/model_selection.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_in = data_in_pruned[np.where((player_ids_pruned != 0) & (player_ids_pruned != 4))]\n",
    "train_out = data_out_pruned[np.where((player_ids_pruned != 0) & (player_ids_pruned != 4))]\n",
    "val_in = data_in_pruned[np.where(player_ids_pruned == 0)]\n",
    "val_out = data_out_pruned[np.where(player_ids_pruned == 0)]\n",
    "test_in = data_in_pruned[np.where(player_ids_pruned == 4)]\n",
    "test_out = data_out_pruned[np.where(player_ids_pruned == 4)]\n",
    "print('Number of training points:', train_in.shape[0])\n",
    "print('Number of validation points:', val_in.shape[0])\n",
    "print('Number of test points:', test_in.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the neural network\n",
    "We use the multilayer perceptron implementation in scikit-learn: http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html\n",
    "\n",
    "When more than a few hyperparameters affects the performance of the model, it becomes impossible to optimise the hyperparameters with a standard grid search. Instead the optimisation is typically done with genetic algorithms or gaussian processes, however any thorough search will be very costly, so here you can just change the hyper parameters by hand.\n",
    "\n",
    "Note: Here we predict all 18 output features with one network. You can definately get better results by training a network a subset of the features. E.g. only predicting the left elbow or even just the X-coordinate of the left elbow.\n",
    "\n",
    "Note: In principle we have twice as many data points if we mirror the body, such that left hand becomes right and vice versa. Try to implement this and see if it improved the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = MLPRegressor(alpha = 1e-4 , hidden_layer_sizes=(64,64), batch_size=2048, early_stopping = True,\n",
    "                         max_iter = 10000, learning_rate_init = 0.01, learning_rate='adaptive')\n",
    "estimator.fit(train_in, train_out)\n",
    "predicted_out = estimator.predict(val_in)\n",
    "val_score = estimator.score(val_in, val_out)\n",
    "score.append(val_score)\n",
    "test_score = np.median(score)\n",
    "print('Pearson correlation on test data: %.3f' % test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we're happy with our choice of hyper parameters, we can include the validation set in the training as well for the final prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_val_in = data_in_pruned[np.where(player_ids_pruned != 4)]\n",
    "train_val_out = data_out_pruned[np.where(player_ids_pruned != 4)]\n",
    "estimator.fit(train_val_in, train_val_out)\n",
    "predicted_out = estimator.predict(test_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatter plots comparing true and predicted values of (x,y,z), here for LeftElbow, indicating the machine learning performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_out[:,6],test_out[:,6],'k')\n",
    "plt.scatter(test_out[:,6],predicted_out[:,6],s=0.5) # Predicted vs true of X coordinates\n",
    "plt.xlabel(\"True X\")\n",
    "plt.ylabel(\"Predicted X\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_out[:,7],test_out[:,7], 'k')\n",
    "plt.scatter(test_out[:,7],predicted_out[:,7],s=0.5) # Predicted vs true of X coordinates\n",
    "plt.xlabel(\"True X\")\n",
    "plt.ylabel(\"Predicted X\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(test_out[:,8],test_out[:,8], 'k')\n",
    "plt.scatter(test_out[:,8],predicted_out[:,8],s=0.5) # Predicted vs true of X coordinates\n",
    "plt.xlabel(\"True X\")\n",
    "plt.ylabel(\"Predicted X\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make violin plots showing the distribution of error for each feature in Euclidean space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of lists of distances between predicted and target for each target position\n",
    "targets_dist = [[] for i in range(test_out.shape[1] // 3)]\n",
    "for test, pred in zip(test_out, predicted_out): \n",
    "    for i in range(len(test) // 3): \n",
    "        test_vec = np.array([test[i * 3 + j] for j in range(3)])\n",
    "        pred_vec = np.array([pred[i * 3 + j] for j in range(3)])\n",
    "        dist = np.linalg.norm(test_vec - pred_vec)\n",
    "        targets_dist[i].append(dist)\n",
    "# convert into numpy array\n",
    "targets_dist = np.array(targets_dist)\n",
    "print(targets_dist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbn.set(font_scale=1.2)\n",
    "# Scale by silvias height\n",
    "scaled_dist = targets_dist * 172\n",
    "df = pd.DataFrame(scaled_dist.T, columns=x)\n",
    "meltdf = df.melt(var_name='Target', value_name='Error (cm)')\n",
    "ax = sbn.violinplot(x=meltdf['Target'], y=meltdf['Error (cm)'])\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Render predicted positions using Unity renderer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../rendering')\n",
    "import AvatarServer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del server\n",
    "except:\n",
    "    print('No server to delete') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = AvatarServer.AvatarServer(port=54321)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to the client. This will block until a client connect.\n",
    "Then send all the features, targets and predicted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server.connect_to_client()\n",
    "\n",
    "# Add back in the Z-component of the head that we removed earlier\n",
    "full_test_in = np.zeros((test_in.shape[0],test_in.shape[1]+1))\n",
    "full_test_in[:,:2] = test_in[:,:2]\n",
    "full_test_in[:,3:] = test_in[:,2:]\n",
    "\n",
    "for f, t, p in zip(full_test_in, test_out, predicted_out):\n",
    "    # TODO - Wrap this up in a nice method.\\n\",\n",
    "    feature_dict = AvatarServer.generate_dictionary_for_data(f, input_labels)\n",
    "    target_dict = AvatarServer.generate_dictionary_for_data(t, output_labels)\n",
    "    pred_dict = AvatarServer.generate_dictionary_for_data(p, output_labels)\n",
    "    message = AvatarServer.merge_dictionaries(feature_dict, target_dict, pred_dict)\n",
    "    server.send_object(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "server.close_connection()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
